# üìä Pr√©diction de la Value-at-Risk : Apprentissage Profond vs Mod√®les Statistiques

> Comparaison des mod√®les d'apprentissage profond (ANN, LSTM) et statistiques (ARIMA, SARIMA) pour la pr√©diction de la Value-at-Risk sur les indices boursiers MENA.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.0+-orange.svg)](https://www.tensorflow.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## üìë Table des Mati√®res

- [√Ä Propos](#√†-propos)
- [Fonctionnalit√©s](#fonctionnalit√©s)
- [Architecture du Projet](#architecture-du-projet)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Donn√©es](#donn√©es)
- [Mod√®les Impl√©ment√©s](#mod√®les-impl√©ment√©s)
- [R√©sultats](#r√©sultats)
- [√âquipe](#√©quipe)
- [R√©f√©rences](#r√©f√©rences)
- [License](#license)

## üéØ √Ä Propos

Ce projet acad√©mique compare l'efficacit√© des **mod√®les d'apprentissage profond** (Deep Learning) et des **mod√®les statistiques classiques** pour la pr√©diction de la **Value-at-Risk (VaR)** sur les march√©s boursiers MENA (Middle East and North Africa).

### Contexte

La Value-at-Risk est une mesure de risque financier largement utilis√©e qui quantifie la perte maximale potentielle sur un horizon temporel donn√© √† un niveau de confiance sp√©cifique. Ce projet explore si les techniques modernes d'apprentissage profond peuvent am√©liorer les pr√©dictions de VaR par rapport aux m√©thodes statistiques traditionnelles.

### Objectifs

- ‚úÖ Impl√©menter et comparer 4 mod√®les de pr√©diction
- ‚úÖ √âvaluer la VaR √† l'aide de la Simulation Historique Bootstrap
- ‚úÖ Valider les r√©sultats par backtesting rigoureux
- ‚úÖ Analyser les performances sur les march√©s MENA

## ‚ö° Fonctionnalit√©s

- **4 Mod√®les de Pr√©diction**
  - üß† ANN (Artificial Neural Network)
  - üîÑ LSTM (Long Short-Term Memory)
  - üìà ARIMA (AutoRegressive Integrated Moving Average)
  - üìä SARIMA (Seasonal ARIMA)

- **Calcul Avanc√© de VaR**
  - Simulation Historique Bootstrap (10,000 √©chantillons)
  - Niveaux de confiance multiples (95%, 99%)
  - Validation par backtesting

- **Analyse Compl√®te**
  - M√©triques de performance (MAE, RMSE)
  - Taux de violations VaR
  - Visualisations d√©taill√©es
  - Tableau de bord de validation automatique

## üìÅ Architecture du Projet

```
var-prediction-project/
‚îÇ
‚îú‚îÄ‚îÄ üìì Projet_VaR_Presentation.ipynb    # Notebook principal (Fran√ßais)
‚îú‚îÄ‚îÄ üìÑ README.md                         # Ce fichier
‚îú‚îÄ‚îÄ üìã requirements.txt                  # D√©pendances Python
‚îÇ
‚îú‚îÄ‚îÄ üìÇ data/
‚îÇ   ‚îú‚îÄ‚îÄ ADI.csv                          # Abu Dhabi Securities Market
‚îÇ   ‚îú‚îÄ‚îÄ MASI.csv                         # Moroccan All Shares Index
‚îÇ   ‚îú‚îÄ‚îÄ TASI.csv                         # Tadawul All Share Index
‚îÇ   ‚îú‚îÄ‚îÄ Tunindex.csv                     # Tunis Stock Exchange
‚îÇ   ‚îú‚îÄ‚îÄ CAC40.csv                        # CAC 40 (Benchmark)
‚îÇ   ‚îú‚îÄ‚îÄ S&P500.csv                       # S&P 500 (Benchmark)
‚îÇ   ‚îú‚îÄ‚îÄ ADITest.csv                      # Donn√©es de test
‚îÇ   ‚îú‚îÄ‚îÄ MASITest.csv
‚îÇ   ‚îú‚îÄ‚îÄ TASITest.csv
‚îÇ   ‚îî‚îÄ‚îÄ TunindexTest.csv
‚îÇ
‚îú‚îÄ‚îÄ üìÇ docs/
‚îÇ   ‚îú‚îÄ‚îÄ methodology.md                   # M√©thodologie d√©taill√©e
‚îÇ   ‚îú‚îÄ‚îÄ results_analysis.md              # Analyse des r√©sultats
‚îÇ   ‚îî‚îÄ‚îÄ references.pdf                   # R√©f√©rences acad√©miques
‚îÇ
‚îî‚îÄ‚îÄ üìÇ outputs/
    ‚îú‚îÄ‚îÄ figures/                         # Graphiques g√©n√©r√©s
    ‚îú‚îÄ‚îÄ models/                          # Mod√®les sauvegard√©s
    ‚îî‚îÄ‚îÄ results/                         # R√©sultats export√©s
```

## üîß Installation

### Pr√©requis

- Python 3.8 ou sup√©rieur
- pip (gestionnaire de paquets Python)
- Compte Google Drive (pour Google Colab)

### Option 1 : Google Colab (Recommand√©)

1. **Ouvrir le notebook dans Colab**
   ```
   https://colab.research.google.com/
   ```

2. **T√©l√©charger le notebook**
   - Uploadez `Projet_VaR_Presentation.ipynb`

3. **Monter Google Drive**
   ```python
   from google.colab import drive
   drive.mount('/content/drive')
   ```

4. **Placer les donn√©es**
   - Cr√©er le dossier `/content/drive/MyDrive/data/`
   - Uploader tous les fichiers CSV

### Option 2 : Installation Locale

1. **Cloner le repository**
   ```bash
   git clone https://github.com/votre-username/var-prediction-project.git
   cd var-prediction-project
   ```

2. **Cr√©er un environnement virtuel**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Sur Windows: venv\Scripts\activate
   ```

3. **Installer les d√©pendances**
   ```bash
   pip install -r requirements.txt
   ```

4. **Lancer Jupyter**
   ```bash
   jupyter notebook Projet_VaR_Presentation.ipynb
   ```

### D√©pendances Principales

```txt
numpy>=1.21.0
pandas>=1.3.0
matplotlib>=3.4.0
seaborn>=0.11.0
tensorflow>=2.8.0
scikit-learn>=0.24.0
statsmodels>=0.13.0
scipy>=1.7.0
```

## üöÄ Utilisation

### Ex√©cution Compl√®te

1. **Ouvrir le notebook** `Projet_VaR_Presentation.ipynb`

2. **Configurer les param√®tres** (Section 2.0)
   ```python
   # Param√®tres du Mod√®le
   LOOKBACK = 10
   RANDOM_SEED = 42
   
   # Param√®tres ANN/LSTM
   ANN_EPOCHS = 200
   LSTM_EPOCHS = 200
   
   # Param√®tres VaR
   N_BOOTSTRAP = 10000
   CONFIDENCE_LEVELS = [0.95, 0.99]
   ```

3. **Ex√©cuter toutes les cellules**
   - Dans Jupyter: `Cell ‚Üí Run All`
   - Dans Colab: `Runtime ‚Üí Run all`

4. **Visualiser les r√©sultats**
   - Section 6: R√©sultats et analyses
   - Section 7: Conclusions
   - Section 8: Validation automatique

### Ex√©cution Rapide (Mode Test)

Pour un test rapide avec moins d'√©poques:

```python
# Configuration rapide
ANN_EPOCHS = 50
LSTM_EPOCHS = 50
N_BOOTSTRAP = 1000
SKIP_SARIMA = True  # SARIMA est le plus lent
```

### Personnalisation

#### Ajouter un Nouvel Indice

1. Placer les fichiers CSV dans `/data/`
2. Modifier la configuration:
   ```python
   data_paths['train']['NOUVEAU_INDICE'] = '/path/to/data.csv'
   data_paths['test']['NOUVEAU_INDICE'] = '/path/to/dataTest.csv'
   mena_indices.append('NOUVEAU_INDICE')
   ```

#### Modifier l'Architecture des Mod√®les

```python
# Section 2.0 - Configuration
ANN_NEURONS = [128, 64, 32]     # Augmenter la capacit√©
LSTM_NEURONS = [128, 64]        # Plus de neurones
LOOKBACK = 20                   # Fen√™tre plus longue
```

## üìä Donn√©es

### Indices MENA

| Indice | Pays | P√©riode | √âchantillons |
|--------|------|---------|--------------|
| **ADI** | √âmirats Arabes Unis | 2015-2024 | ~2500 |
| **MASI** | Maroc | 2015-2024 | ~2500 |
| **TASI** | Arabie Saoudite | 2015-2024 | ~2500 |
| **Tunindex** | Tunisie | 2015-2024 | ~2500 |

### Indices de R√©f√©rence

| Indice | R√©gion | Usage |
|--------|--------|-------|
| **CAC40** | Europe | Benchmark d√©velopp√© |
| **S&P500** | USA | Benchmark mondial |

### Format des Donn√©es

```csv
Date,Price,Open,High,Low,Vol.,Change %
Dec 31, 2014,4528.93,4441.67,4554.09,4424.24,213.88M,1.91%
Dec 30, 2014,4444.03,4543.14,4543.14,4416.47,178.16M,-2.18%
...
```

## ü§ñ Mod√®les Impl√©ment√©s

### 1. ANN (R√©seau de Neurones Artificiels)

**Architecture:**
```
Input (10) ‚Üí Dense(64) ‚Üí Dropout(0.2) ‚Üí 
Dense(32) ‚Üí Dropout(0.2) ‚Üí Dense(16) ‚Üí 
Dropout(0.1) ‚Üí Output(1)
```

**Avantages:**
- Capture les relations non-lin√©aires
- Entra√Ænement rapide
- Bonne g√©n√©ralisation

### 2. LSTM (Long Short-Term Memory)

**Architecture:**
```
Input (10, 1) ‚Üí LSTM(64) ‚Üí Dropout(0.2) ‚Üí 
LSTM(32) ‚Üí Dropout(0.2) ‚Üí Dense(16) ‚Üí Output(1)
```

**Avantages:**
- M√©moire √† long terme
- Capture les d√©pendances temporelles
- Excellent pour les s√©ries temporelles

### 3. ARIMA

**Configuration:**
- Ordre optimal s√©lectionn√© par AIC
- Range: p,d,q ‚àà [0,3]
- Pr√©diction rolling window

**Avantages:**
- Interpr√©table
- Robuste
- Peu de param√®tres

### 4. SARIMA

**Configuration:**
- P√©riode saisonni√®re: 5 jours (hebdomadaire)
- Ordre saisonnier: P,D,Q ‚àà [0,2]
- Selection automatique par AIC

**Avantages:**
- Capture la saisonnalit√©
- Extension naturelle d'ARIMA
- Bonne pour patterns cycliques

## üìà R√©sultats

### Performance Moyenne (MAE)

| Mod√®le | MAE Moyen | Rang |
|--------|-----------|------|
| **LSTM** | 0.005633 | ü•á 1 |
| **ANN** | 0.005688 | ü•à 2 |
| **SARIMA** | 0.005819 | ü•â 3 |
| **ARIMA** | 0.005831 | 4 |

### Estimations VaR (Moyennes)

| Mod√®le | VaR 95% | VaR 99% |
|--------|---------|---------|
| **ANN** | 0.0125 | 0.0224 |
| **LSTM** | 0.0126 | 0.0226 |
| **ARIMA** | 0.0126 | 0.0224 |
| **SARIMA** | 0.0123 | 0.0219 |

### Backtesting (Taux de Violations)

| Mod√®le | Violations 95% | Violations 99% | Statut |
|--------|----------------|----------------|--------|
| **ANN** | 5.32% | 1.10% | ‚úÖ Excellent |
| **LSTM** | 5.32% | 1.10% | ‚úÖ Excellent |
| **ARIMA** | 5.32% | 1.10% | ‚úÖ Excellent |
| **SARIMA** | 5.32% | 1.10% | ‚úÖ Excellent |

> üìå **Note:** Violations attendues = 5.00% pour VaR 95%, 1.00% pour VaR 99%

### Validation Compl√®te

```
‚úÖ TOUTES LES V√âRIFICATIONS R√âUSSIES!
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚úì VaR dans plage r√©aliste
‚úì VaR 99% > VaR 95%
‚úì Toutes valeurs positives
‚úì Violations acceptables
‚úì Couverture ad√©quate
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
6/6 v√©rifications r√©ussies (100%)
```

## üéì √âquipe

Ce projet a √©t√© d√©velopp√© par :

- **Aws Ourari** - [GitHub](https://github.com/aws-ourari) | [LinkedIn](https://linkedin.com/in/aws-ourari)
- **Nairi Najla** - [GitHub](https://github.com/nairi-najla) | [LinkedIn](https://linkedin.com/in/nairi-najla)
- **Ines Jaziri** - [GitHub](https://github.com/ines-jaziri) | [LinkedIn](https://linkedin.com/in/ines-jaziri)

> üìß Pour toute question : [aws.ourari@example.com](mailto:aws.ourari@example.com)

## üìö R√©f√©rences

### Articles Scientifiques

1. **Kupiec, P. H.** (1995). *Techniques for verifying the accuracy of risk measurement models.* Journal of Derivatives, 3(2), 73-84.

2. **Christoffersen, P. F.** (1998). *Evaluating interval forecasts.* International Economic Review, 39(4), 841-862.

3. **Hochreiter, S., & Schmidhuber, J.** (1997). *Long short-term memory.* Neural Computation, 9(8), 1735-1780.

4. **Box, G. E., et al.** (2015). *Time series analysis: forecasting and control.* John Wiley & Sons.

5. **Efron, B., & Tibshirani, R. J.** (1994). *An introduction to the bootstrap.* CRC Press.

### Documentation Technique

- [TensorFlow Documentation](https://www.tensorflow.org/api_docs)
- [Statsmodels Documentation](https://www.statsmodels.org/)
- [Scikit-learn Documentation](https://scikit-learn.org/stable/)

## üìù License

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

```
MIT License

Copyright (c) 2026 Aws Ourari, Nairi Najla, Ines Jaziri

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
```

## üôè Remerciements

- Professeurs et encadrants acad√©miques
- Communaut√© open-source (TensorFlow, Statsmodels)
- Fournisseurs de donn√©es boursi√®res
- Tous ceux qui ont contribu√© √† ce projet

## üêõ Bugs et Suggestions

Si vous trouvez des bugs ou avez des suggestions d'am√©lioration :

1. **Ouvrir une issue** sur GitHub
2. **Fork** le projet et cr√©er une pull request
3. **Contacter** l'√©quipe directement

## üìä Statistiques du Projet

![Lines of Code](https://img.shields.io/badge/Lines%20of%20Code-2000+-blue)
![Commits](https://img.shields.io/badge/Commits-50+-green)
![Contributors](https://img.shields.io/badge/Contributors-3-orange)

---

<div align="center">

**‚≠ê Si ce projet vous est utile, n'h√©sitez pas √† lui donner une √©toile! ‚≠ê**

Made with ‚ù§Ô∏è by [Aws Ourari](https://github.com/aws-ourari), [Nairi Najla](https://github.com/nairi-najla), [Ines Jaziri](https://github.com/ines-jaziri)

</div>
